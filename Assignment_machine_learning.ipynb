{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31e0bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # 1\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier # 2\n",
    "from sklearn.linear_model import LogisticRegression# 3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f65c446c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>gender</th>\n",
       "      <th>days</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14235</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16790</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17520</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22265</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16790</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17520</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16060</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18980</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14600</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14235</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0             4              0         0.0     0.0                0   \n",
       "1             2              0         0.0     0.0                0   \n",
       "2             1              1        20.0     0.0                0   \n",
       "3             3              1        30.0     0.0                0   \n",
       "4             3              1        23.0     0.0                0   \n",
       "...         ...            ...         ...     ...              ...   \n",
       "4235          2              1        20.0     0.0                0   \n",
       "4236          1              1        15.0     0.0                0   \n",
       "4237          2              0         0.0     0.0                0   \n",
       "4238          3              0         0.0     0.0                0   \n",
       "4239          3              1        30.0     0.0                0   \n",
       "\n",
       "      prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  \\\n",
       "0                0         0    195.0  106.0   70.0  26.97       80.0   \n",
       "1                0         0    250.0  121.0   81.0  28.73       95.0   \n",
       "2                0         0    245.0  127.5   80.0  25.34       75.0   \n",
       "3                1         0    225.0  150.0   95.0  28.58       65.0   \n",
       "4                0         0    263.0  130.0   84.0  23.10       85.0   \n",
       "...            ...       ...      ...    ...    ...    ...        ...   \n",
       "4235             0         0    248.0  131.0   72.0  22.00       84.0   \n",
       "4236             0         0    210.0  126.5   87.0  19.16       86.0   \n",
       "4237             0         0    263.0  133.5   83.0  21.47       80.0   \n",
       "4238             1         0    185.0  141.0   98.0  25.60       67.0   \n",
       "4239             0         0    196.0  133.0   86.0  20.91       85.0   \n",
       "\n",
       "         glucose  TenYearCHD  gender   days  age  \n",
       "0      77.000000           0       1  14235   39  \n",
       "1      76.000000           0       0  16790   46  \n",
       "2      70.000000           0       1  17520   48  \n",
       "3     103.000000           0       0  22265   61  \n",
       "4      85.000000           0       0  16790   46  \n",
       "...          ...         ...     ...    ...  ...  \n",
       "4235   86.000000           0       0  17520   48  \n",
       "4236   81.963655           0       0  16060   44  \n",
       "4237  107.000000           0       0  18980   52  \n",
       "4238   72.000000           0       1  14600   40  \n",
       "4239   80.000000           0       0  14235   39  \n",
       "\n",
       "[4240 rows x 17 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fram')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bf2e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df.drop(columns=['TenYearCHD'], axis=0)\n",
    "y = df.TenYearCHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e496f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>gender</th>\n",
       "      <th>days</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14235</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16790</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17520</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22265</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16790</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0          4              0         0.0     0.0                0   \n",
       "1          2              0         0.0     0.0                0   \n",
       "2          1              1        20.0     0.0                0   \n",
       "3          3              1        30.0     0.0                0   \n",
       "4          3              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    263.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   gender   days  age  \n",
       "0       1  14235   39  \n",
       "1       0  16790   46  \n",
       "2       1  17520   48  \n",
       "3       0  22265   61  \n",
       "4       0  16790   46  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a233d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e204b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=.25, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7655d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_shape (3180, 16)\n",
      "X_te_shape (1060, 16)\n",
      "y_tr_shape (3180,)\n",
      "y_te_shape (1060, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_tr_shape\", X_train.shape)\n",
    "print(\"X_te_shape\", X_test.shape)\n",
    "print(\"y_tr_shape\", y_train.shape)\n",
    "print(\"y_te_shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a2648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8641a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cc3ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "506c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6172b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('array:',y_test[:25].to_list())\n",
    "y_pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d45df250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7c079e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TenYearCHD'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.TenYearCHD.value_counts().plot(kind='bar', grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd53c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=.25, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6ac47b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (3180, 16)\n",
      "X_test shape:  (1060, 16)\n",
      "y_train shape:  (3180,)\n",
      "y_test shape:  (1060,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0b32db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fc0a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5726aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5e66799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ce33d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4038a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=.25, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97464f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (3180, 16)\n",
      "X_test shape:  (1060, 16)\n",
      "y_train shape:  (3180,)\n",
      "y_test shape:  (1060,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb0a82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = LogisticRegression ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6a07b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lre\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "lre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0022a6b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lre\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "y_pred = lre.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a35fc60",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lre\u001b[38;5;241m.\u001b[39mscore(X_train,y_train)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\.anaconda\\naat anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "lre.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bb8e99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28179978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
